<html>
<head>
  <meta charset="utf-8">
  <title>XAI and Trust</title>

  <link href='https://fonts.googleapis.com/css?family=Overpass' rel='stylesheet'>
  <link rel="stylesheet" href="font-awesome-4.7.0/css/font-awesome.min.css">
  <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet">
  <link href="mainpage.css" rel="stylesheet">
</head>

<body>


<!-- Lab logo -->
<div class="row" style="text-align:center;padding:0;padding-top:20;padding-bottom:10;margin:0">
  <div class="container">
    <img src="imgs/acks.png" height="70px" style="vertical-align:middle">
    <!--<span style="font-size:32px;vertical-align:middle"><a href="https://visualai.princeton.edu" style="color:#ff8f00" target="_blank">Princeton Visual AI Lab</a></span> -->
  </div>
</div>


<!-- Authors -->
<div class="container-fluid">
  
  <div class="row">
    <h1><span style="font-size:50px;color:#333;font-weight:800">Understanding Explainable AI and Trust</span></h1>
    <br/>
    <div class="authors">
      <span style="font-size:18px"><a href="https://www.cs.princeton.edu/~suhk/" style="color:#1075bc" target="new">Sunnie S. Y. Kim</a></span>
      &nbsp;
      <span style="font-size:18px"><a href="http://www.elizabethannewatkins.com/" style="color:#1075bc" target="new">Elizabeth Anne Watkins</a></span>
      &nbsp;
      <span style="font-size:18px"><a href="https://www.cs.princeton.edu/~olgarus/" style="color:#1075bc" target="new">Olga Russakovsky</a></span>
      &nbsp;
      <span style="font-size:18px"><a href="https://ruthcfong.github.io/" style="color:#1075bc" target="new">Ruth Fong</a></span>
      &nbsp;
      <span style="font-size:18px"><a href="https://www.andresmh.com/" style="color:#1075bc" target="new">Andr√©s Monroy-Hern√°ndez</a></span>
      <br>
    </div>
  </div>
  
  <!--
  <div class="row" style="text-align:center;padding:0;padding-top:20;padding-bottom:10;margin:0">
    <div class="container">
      <img src="imgs/authors.png" height="125px" style="vertical-align:middle">
    </div>
  </div>
  -->

</div>
  
<!-- Overview -->
<div class="container">
  <!--<h2>Overview</h2>-->
  We conducted an in-depth qualitative study with end-users of a real-world AI application to gain a nuanced understanding of explainable AI and trust.
  <br />
  <br />
  In paper 1 on explainable AI, we discuss (1) what explainability needs end-users had, 
  (2) how they intended to use explanations of AI outputs, 
  and (3) how they perceived existing explanation approaches.
  <br />
  <br />
  In paper 2 on trust, we describe three aspects of end-users' trust in AI 
  and how human, AI, and context-related factors influenced each.
  <br />
  <br />
  See the below video for an overview of paper 1.
</div>
  
&nbsp;
  
<div class="container">
  <div style="width: 75%;height: 0;padding-bottom: 42%;position: relative;margin-left: auto;margin-right: auto;">
    <iframe src="https://youtube.com/embed/IcVsi5-ON4Y" allowfullscreen style="position: absolute; width: 100%; height: 100%; left: 0; top: 0;"></iframe>
  </div>
  
</div>
  
&nbsp;

<div class="container-fluid"></div>


<!--
<div class="container">
  <h2>News</h2>
  04/2023: <a href="https://sunniesuhyoung.github.io/XAI_Trust/" target="_blank">Humans, AI, and Context</a> was accepted to <a href="https://facctconference.org/" target="_blank">FAccT 2023</a>.
  <br />
  <br />
  04/2023: <a href="https://arxiv.org/abs/2210.03735" target="_blank">"Help Me Help the AI"</a> received a Best Paper Honorable MentionüèÖ at <a href="https://chi2023.acm.org/" target="_blank">CHI 2023</a>.
  <br />
  <br />
  03/2023: <a href="" target="_blank">Humans, AI, and Context</a> was accepted to the <a href="https://chi-trait.github.io/" target="_blank">CHI 2023 Trust and Reliance in AI-assisted Tasks (TRAIT) Workshop</a>.
  <br />
  <br />
  03/2023: We reflected on our findings from <a href="https://arxiv.org/abs/2210.03735" target="_blank">"Help Me Help the AI"</a>
  and wrote a position paper <a href="https://sunniesuhyoung.github.io/XAI_Trust/" target="_blank">Explainable AI for End-Users</a>.
  We will be presenting it at the <a href="https://hcxai.jimdosite.com/" target="_blank">CHI 2023 Human-Centered Explainable AI (HCXAI) Workshop</a>.
  <br />
  <br />
  01/2023: <a href="https://arxiv.org/abs/2210.03735" target="_blank">"Help Me Help the AI"</a> was accepted to <a href="https://chi2023.acm.org/" target="_blank">CHI 2023</a>.
  <br />
  <br />
  12/2022: We reflected on our findings from <a href="https://arxiv.org/abs/2210.03735" target="_blank">"Help Me Help the AI"</a>
  and wrote a position paper  <a href="https://github.com/sunniesuhyoung/publicfiles/blob/main/Kim2022HCAI.pdf" target="_blank">Closing the Creator-Consumer Gap in XAI: A Call for Participatory XAI Design with End-users</a>.
  We gave a panel presentation on it at the <a href="https://hcai-at-neurips.github.io/site/index.html" target="_blank"> NeurIPS 2022 Human-Centered AI (HCAI) Workshop</a>.
  <br />
  <br />
  10/2022: We posted a preprint of <a href="https://arxiv.org/abs/2210.03735" target="_blank">"Help Me Help the AI": Understanding How Explainability Can Support Human-AI Interaction</a>.

</div>
-->
  
  
<!-- Paper 1 -->
<div class="container">
  <h2>Paper 1 on Explainable AI</h2>
  <a href="https://arxiv.org/abs/2210.03735" target="_blank">"Help Me Help the AI": Understanding How Explainability Can Support Human-AI Interaction</a>
  <br />
  <a href="https://chi2023.acm.org/" style="color:#000000" target="_blank">CHI 2023</a>
  <span style="color:#f09228">Best Paper Honorable Mention</span>üèÖ
  <br />
  <br />
  Despite the proliferation of explainable AI (XAI) methods, 
  little is understood about end-users' explainability needs and behaviors around XAI explanations. 
  To address this gap and contribute to understanding how explainability can support human-AI interaction, 
  we conducted a mixed-methods study with 20 end-users of a real-world AI application, 
  the Merlin bird identification app, and inquired about their XAI needs, uses, and perceptions. 
  We found that participants desire practically useful information that can improve their 
  collaboration with the AI, more so than technical system details. 
  Relatedly, participants intended to use XAI explanations for various purposes 
  beyond understanding the AI's outputs: calibrating trust, improving their task skills, 
  changing their behavior to supply better inputs to the AI, and giving constructive feedback to developers. 
  Finally, among existing XAI approaches, participants preferred part-based explanations 
  that resemble human reasoning and explanations. 
  We discuss the implications of our findings and provide recommendations for future XAI design.
  <br />
  <br />
  Position papers based on this work were accepted to
  <a href="https://hcxai.jimdosite.com/" style="color:#000000" target="_blank">CHI 2023 Human-Centered Explainable AI (HCXAI) Workshop</a>
  and
  <a href="https://hcai-at-neurips.github.io/site/index.html" style="color:#000000" target="_blank">NeurIPS 2022 Human-Centered AI (HCAI) Workshop</a>
  as <span style="color:#f09228">panel presentation</span>.
</div>
  
&nbsp;
  
<div class="container-fluid"></div>
  
<!-- Icons -->
<div class="container">
  <div class="row">
    <div class="col-lg-0 col-md-0 col-sm-0"></div>

    <div class="col-xs-2 col-xs-offset-0 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://arxiv.org/abs/2210.03735" target="_blank">
          <i class="fa fa-4x fa-file-text-o text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">Paper</h4>
      </div>
    </div>

    <div class="col-xs-2 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://github.com/sunniesuhyoung/publicfiles/blob/main/Kim2023HelpMeHelpTheAI_supp.pdf" target="_blank">
          <i class="fa fa-4x fa-file-text-o text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">Supplement</h4>
      </div>
    </div>

    <div class="col-xs-2 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://youtu.be/PD8a7aEQPf4" target="_blank">
          <i class="fa fa-4x fa-youtube-play text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">30sec Preview</h4>
      </div>
    </div>

    <div class="col-xs-2 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://youtu.be/IcVsi5-ON4Y" target="_blank">
          <i class="fa fa-4x fa-youtube-play text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">10min Talk</h4>
      </div>
    </div>
    
    
    <div class="col-xs-2 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://drive.google.com/file/d/1nOYfy_0e61cGGDzwreCI4IUly1VbTgur/view?usp=sharing" target="_blank">
          <i class="fa fa-4x fa-file-text-o text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">CHI HCXAI Workshop Paper</h4>
      </div>
    </div>
    
    <div class="col-xs-2 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://drive.google.com/file/d/1nOYfy_0e61cGGDzwreCI4IUly1VbTgur/view?usp=sharing" target="_blank">
          <i class="fa fa-4x fa-file-text-o text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">NeurIPS HCAI Workshop Paper</h4>
      </div>
    </div>

  </div>
</div>
  
  
<!-- Paper 2 -->
<div class="container">
  <h2>Paper 2 on Trust</h2>
  <a href="https://sunniesuhyoung.github.io/XAI_Trust/" target="_blank">Humans, AI, and Context: Understanding End-Users‚Äô Trust in a Real-World Computer Vision Application</a>
  <br />
  <a href="https://facctconference.org/" style="color:#000000" target="_blank">FAccT 2023</a>
  <br />
  <br />
  Trust is an important factor in people's interactions with AI systems. 
  However, there is a lack of empirical studies examining how end-users trust AI in real-world contexts. 
  Most research investigates one aspect of trust in lab settings with hypothetical end-users. 
  In this paper, we provide a holistic and nuanced understanding of trust in AI through a 
  qualitative case study of a real-world computer vision AI application. 
  We report findings from interviews with 20 end-users of an app for bird identification 
  where we inquired about their trust in the app from many angles. 
  We find participants perceived the app as trustworthy and trusted it, 
  but selectively accepted app outputs only after engaging in verification behaviors, 
  and decided against app adoption in certain high-stakes scenarios. 
  We also find domain knowledge and context are important and influential factors of participants' 
  trust-based cognitive assessments and behavioral decision-making. 
  We discuss the implications of our findings and provide recommendations for future research.
  <br />
  <br />
  Shorter version of this work was accepted to
  <a href="https://chi-trait.github.io/" style="color:#000000" target="_blank">CHI 2023 Trust and Reliance in AI-assisted Tasks (TRAIT) Workshop</a>.
</div>
  
  
<!--
<div class="container">
  <div class="row">
    <div class="col-lg-0 col-md-0 col-sm-0"></div>

    <div class="col-xs-2 col-xs-offset-2 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://arxiv.org/abs/2112.03184" target="_blank">
          <i class="fa fa-4x fa-file-text-o text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">Paper</h4>
      </div>
    </div>

    <div class="col-xs-2 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://github.com/princetonvisualai/HIVE/blob/main/materials/HIVE_suppmat.pdf" target="_blank">
          <i class="fa fa-4x fa-file-text-o text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">Supplement</h4>
      </div>
    </div>

    <div class="col-xs-2 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://drive.google.com/file/d/1nOYfy_0e61cGGDzwreCI4IUly1VbTgur/view?usp=sharing" target="_blank">
          <i class="fa fa-4x fa-file-text-o text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">Extended Abstract</h4>
      </div>
    </div>

    <div class="col-xs-1 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://github.com/princetonvisualai/HIVE/blob/main/materials/1511.pdf" target="_blank">
          <i class="fa fa-4x fa-list-alt text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">Poster</h4>
      </div>
    </div>

    <div class="col-xs-1 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://youtu.be/BDlFb1CFQRQ" target="_blank">
          <i class="fa fa-4x fa-youtube-play text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">2min Talk</h4>
      </div>
    </div>

    <div class="col-xs-1 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://youtu.be/Wm-r-jtSrF8" target="_blank">
          <i class="fa fa-4x fa-youtube-play text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">4min Talk</h4>
      </div>
    </div>

    <div class="col-xs-1 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://youtu.be/7uysq-qAtr4" target="_blank">
          <i class="fa fa-4x fa-youtube-play text-primary mb-3"></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">8min Talk</h4>
      </div>
    </div>

    <div class="col-xs-1 text-center">
      <div class="service-box mt-5 mx-auto">
        <a href="https://github.com/princetonvisualai/HIVE" target="_blank">
          <i class="fa fa-4x fa-github text-primary mb-3 "></i>
        </a>
        <h4 class="mb-3" style="font-size:14px">Code</h4>
        </div>
    </div>

  </div>
</div>
-->

&nbsp;
  
<div class="container-fluid"></div>

<!-- Citation -->
<div class="container">
  <h2>Citation</h2>
  <pre><code>
    @inproceedings{kim2023helpmehelptheai,
      author = {Sunnie S. Y. Kim and Elizabeth Anne Watkins and Olga Russakovsky and Ruth Fong and Andr√©s Monroy-Hern√°ndez},
      title = {"Help Me Help the {AI}": Understanding How Explainability Can Support Human-{AI} Interaction},
      booktitle = {ACM Conference on Human Factors in Computing Systems (CHI)},
      year = {2023}
    }
    
    @inproceedings{kim2023trust,
      author = {Sunnie S. Y. Kim and Elizabeth Anne Watkins and Olga Russakovsky and Ruth Fong and Andr√©s Monroy-Hern√°ndez},
      title = {Humans, {AI}, and Context: Understanding End-Users‚Äô Trust in a Real-World Computer Vision Application},
      booktitle = {ACM Conference on Fairness, Accountability, and Transparency (FAccT)},
      year = {2023}
    }
  </code></pre>
</div>

<!-- Acknowledgements -->
<div class="container">
  <h2>Acknowledgements</h2>

  We foremost thank our participants for generously sharing their time and experiences.
  We also thank Tristen Godfrey, Dyanne Ahn, and Klea Tryfoni for their help in interview transcription.
  Finally, we thank Angelina Wang, Vikram V. Ramaswamy, Amna Liaqat, Fannie Liu, and other members of the 
  Princeton HCI Lab and the Princeton Visual AI Lab for their helpful and thoughtful feedback.
  
  <br />
  <br />
  
  This material is based upon work partially supported by the National Science Foundation (NSF) under 
  Grants 1763642 and 2145198 awarded to OR. Any opinions, findings, and conclusions or recommendations expressed 
  in this material are those of the authors and do not necessarily reflect the views of the NSF.
  We also acknowledge support from the Princeton SEAS Howard B. Wentz, Jr. Junior Faculty Award (OR), 
  Princeton SEAS Project X Fund (RF, OR), Princeton Center for Information Technology Policy (EW), 
  Open Philanthropy (RF, OR), and NSF Graduate Research Fellowship (SK).

</div>

<div class="container" >
  <h2>Contact</h2>
  <div><a href="https://www.cs.princeton.edu/~suhk/" target="_blank">Sunnie S. Y. Kim</a> (sunniesuhyoung@princeton.edu)</div>
</div>

<div id="footer">
</div>


</body>
</html>
